{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guE34D3Fj2R9"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V57zhcTp1Xxb"
      },
      "source": [
        "Objectives:\n",
        "* Solve a regression problem with deep neural networks (DNN).\n",
        "* Understand basic DNN training tips.\n",
        "* Familiarize yourself with PyTorch.\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUATI4ONArv_",
        "outputId": "388e05fc-46a9-4534-be72-d21ed4e0cb17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Apr 19 22:00:53 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 537.79                 Driver Version: 537.79       CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA T600 Laptop GPU       WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   59C    P8              N/A / ERR! |    735MiB /  4096MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A     31672      C   D:\\Anaconda\\envs\\pytorch\\python.exe       N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check gpu type\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igqIMEgu64-F"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "xybQNYCXYu13"
      },
      "outputs": [],
      "source": [
        "# Numerical Operations\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Reading/Writing Data\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# For Progress Bar\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# Pytorch\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# For plotting learning curve\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Optuna 调参\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTAVqRfc2KK3"
      },
      "source": [
        "# Some Utility Functions\n",
        "\n",
        "You do not need to modify this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "RbrcpfYN2I-H"
      },
      "outputs": [],
      "source": [
        "def same_seed(seed): \n",
        "    '''Fixes random number generator seeds for reproducibility.'''\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_valid_split(data_set, valid_ratio, seed):\n",
        "    '''Split provided training data into training set and validation set'''\n",
        "    valid_set_size = int(valid_ratio * len(data_set)) \n",
        "    train_set_size = len(data_set) - valid_set_size\n",
        "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
        "    return np.array(train_set), np.array(valid_set)\n",
        "\n",
        "def predict(test_loader, model, device):\n",
        "    model.eval() # Set your model to evaluation mode.\n",
        "    preds = []\n",
        "    for x in test_loader:\n",
        "        x = x.to(device)                        \n",
        "        with torch.no_grad():                   \n",
        "            pred = model(x)                     \n",
        "            preds.append(pred.detach().cpu())   \n",
        "    preds = torch.cat(preds, dim=0).numpy()  \n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqO3lTm78nNO"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "-mjaJM0wprMs"
      },
      "outputs": [],
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    '''\n",
        "    x: Features.\n",
        "    y: Targets, if none, do prediction.\n",
        "    '''\n",
        "    def __init__(self, x, y=None):\n",
        "        if y is None:\n",
        "            self.y = y\n",
        "        else:\n",
        "            self.y = torch.FloatTensor(y)\n",
        "        self.x = torch.FloatTensor(x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.x[idx]\n",
        "        else:\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m73ooU75CL_j"
      },
      "source": [
        "# Neural Network Model\n",
        "Try out different model architectures by modifying the class below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "Qn97_WvvrEkG"
      },
      "outputs": [],
      "source": [
        "class My_Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(My_Model, self).__init__()\n",
        "        # TODO: modify model's structure, be aware of dimensions. \n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.squeeze(1) # (B, 1) -> (B)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5-LKF6R8xeq"
      },
      "source": [
        "# Feature Selection\n",
        "Choose features you deem useful by modifying the function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "0FEnKRaIIeKp"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression # type: ignore\n",
        "\n",
        "def select_feat(train_data, valid_data, test_data, no_select_all=True):\n",
        "    '''Selects useful features to perform regression'''\n",
        "    global config\n",
        "    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
        "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n",
        "\n",
        "    if not no_select_all:\n",
        "        feat_idx = list(range(raw_x_train.shape[1]))\n",
        "    else:\n",
        "        # feat_idx = [0,1,2,3,4] # TODO: Select suitable feature columns.\n",
        "        k = config['k']\n",
        "        selector = SelectKBest(score_func=f_regression, k=k)\n",
        "        result = selector.fit(train_data[:, 35:-1], train_data[:, -1])\n",
        "        idx = np.argsort(result.scores_)[::-1]\n",
        "        feat_idx = list(np.sort(idx[:k]))\n",
        "        # feat_idx = list([34, 36, 51, 52, 54, 70, 72, 69])\n",
        "        \n",
        "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kADIPNQ2Ih5X"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "k4Rq8_TztAhq"
      },
      "outputs": [],
      "source": [
        "def trainer(train_loader, valid_loader, model, config, device):\n",
        "    print('training...')\n",
        "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
        "\n",
        "    # Define your optimization algorithm. \n",
        "    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
        "    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n",
        "    if config['optim'] == 'SGD':\n",
        "        if config['no_momentum']:\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "        else:\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=config['momentum'], weight_decay=config['weight_decay'])\n",
        "    elif config['optim'] == 'Adam':\n",
        "        optimizer = torch.optim.Adam(model.paremeters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "    \n",
        "    \n",
        "    \n",
        "    writer = SummaryWriter() # Writer of tensoboard.\n",
        "\n",
        "    if not os.path.isdir('./models'):\n",
        "        os.mkdir('./models') # Create directory of saving models.\n",
        "\n",
        "    n_epochs, best_loss, step, early_stop_count= config['n_epochs'], math.inf, 0, 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # Set your model to train mode.\n",
        "        loss_record = []\n",
        "\n",
        "        # tqdm is a package to visualize your training progress.\n",
        "        # train_pbar = tqdm(train_loader, position=0, leave=True)\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            optimizer.zero_grad()               # Set gradient to zero.\n",
        "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
        "            pred = model(x)             \n",
        "            loss = criterion(pred, y)\n",
        "            loss.backward()                     # Compute gradient(backpropagation).\n",
        "            optimizer.step()                    # Update parameters.\n",
        "            step += 1\n",
        "            loss_record.append(loss.detach().item())\n",
        "            \n",
        "            # Display current epoch number and loss on tqdm progress bar.\n",
        "            # train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
        "            # train_pbar.set_postfix({'loss': loss.detach().item()})\n",
        "\n",
        "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
        "        # writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "\n",
        "        model.eval() # Set your model to evaluation mode.\n",
        "        loss_record = []\n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                loss = criterion(pred, y)\n",
        "\n",
        "            loss_record.append(loss.item())\n",
        "            \n",
        "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
        "        # print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
        "        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
        "        if not config['no_tensorboard']:\n",
        "            writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "            writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if mean_valid_loss < best_loss:\n",
        "            best_loss = mean_valid_loss\n",
        "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
        "            print('Saving model with loss {:.3f}...'.format(best_loss))         \n",
        "            # print('Saving model with loss {:.3f}...'.format(best_loss))\n",
        "\n",
        "            early_stop_count = 0\n",
        "        else: \n",
        "            early_stop_count += 1\n",
        "\n",
        "        \n",
        "        if early_stop_count >= config['early_stop']:\n",
        "            print('\\nModel is not improving, so we halt the training session.')\n",
        "            break\n",
        "    return best_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pgkOh2e9UjE"
      },
      "source": [
        "# Configurations\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "QoWPUahCtoT6"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "config = {\n",
        "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
        "    'valid_ratio': 0.1,   # validation_size = train_size * valid_ratio\n",
        "    'n_epochs': 10000,     # Number of epochs.            \n",
        "    'batch_size': 256, \n",
        "    'learning_rate': 1e-5,\n",
        "    'weight_decay': 1e-5,              \n",
        "    'early_stop': 1000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
        "    'save_path': './models/best_model.ckpt',  # Your model will be saved here.\n",
        "    'layer': [16, 16],   # NN结点数\n",
        "    'k': 16,    # 选择k个特征\n",
        "    'optim': 'SGD',\n",
        "    'momentum': 0.7,\n",
        "    'no_select_all': True,  # 是否选择全部特征\n",
        "    'no_momentum': False,    # 是否使用动量\n",
        "    'no_normal': True,      # 是否归一化数据\n",
        "    # 'no_k_cross': False,    # 是否K折交叉验证\n",
        "    'no_save': False,       # 是否保存模型\n",
        "    'no_tensorboard': True # 是否记录训练过程\n",
        "}\n",
        "# 设置 k-fold 中的 k，这里是根据 valid_ratio 设定的\n",
        "# k = int(1 / config['valid_ratio'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OBYgjCA-YwD"
      },
      "source": [
        "# Start training!\n",
        "``config``包含需要调整的超参数和模型保存路径\n",
        "\n",
        "``objective()``可以自动调参, 设置``AUTO_TUNE_PARAM``为``False``可以取消 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdttVRkAfu2t",
        "outputId": "92145ff1-e4a3-4194-bb1a-ebe94176f091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You could set AUTO_TUNE_PARAM True to tune parameters automatically.\n",
            "AUTO_TUNE_PARAM: False\n",
            "hyper-parameter: \n",
            "        optimizer: SGD,\n",
            "        lr: 1e-05, \n",
            "        momentum: 0.7,\n",
            "        select_feats: 16, \n",
            "        layer: [16, 16]\n",
            "train_data size: (2709, 16) \n",
            "    valid_data size: (300, 16) \n",
            "    test_data size: (997, 16)\n",
            "training...\n",
            "Saving model with loss 465.029...\n",
            "Saving model with loss 409.405...\n",
            "Saving model with loss 393.558...\n",
            "Saving model with loss 381.241...\n",
            "Saving model with loss 367.695...\n",
            "Saving model with loss 365.394...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model with loss 359.091...\n",
            "Saving model with loss 351.640...\n",
            "Saving model with loss 349.572...\n",
            "Saving model with loss 340.735...\n",
            "Saving model with loss 338.859...\n",
            "Saving model with loss 337.285...\n",
            "Saving model with loss 324.225...\n",
            "Saving model with loss 311.644...\n",
            "Saving model with loss 290.031...\n",
            "Saving model with loss 277.639...\n",
            "Saving model with loss 274.475...\n",
            "Saving model with loss 271.205...\n",
            "Saving model with loss 263.278...\n",
            "Saving model with loss 125.993...\n",
            "Saving model with loss 95.050...\n",
            "Saving model with loss 84.723...\n",
            "Saving model with loss 79.207...\n",
            "Saving model with loss 78.528...\n",
            "Saving model with loss 76.781...\n",
            "Saving model with loss 71.727...\n",
            "Saving model with loss 61.277...\n",
            "Saving model with loss 60.844...\n",
            "Saving model with loss 60.083...\n",
            "Saving model with loss 59.602...\n",
            "Saving model with loss 59.552...\n",
            "Saving model with loss 54.933...\n",
            "Saving model with loss 51.905...\n",
            "Saving model with loss 51.110...\n",
            "Saving model with loss 48.015...\n",
            "Saving model with loss 47.714...\n",
            "Saving model with loss 43.384...\n",
            "Saving model with loss 43.030...\n",
            "Saving model with loss 38.517...\n",
            "Saving model with loss 38.083...\n",
            "\n",
            "Model is not improving, so we halt the training session.\n",
            "best_loss: 38.082881927490234\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility\n",
        "same_seed(config['seed'])\n",
        "\n",
        "train_data, test_data = pd.read_csv('./covid_train.csv').values, pd.read_csv('./covid_test.csv').values\n",
        "train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
        "\n",
        "# num_valid_samples = len(training_data) // k\n",
        "# np.random.shuffle(training_data)\n",
        "valid_losses = []  # 记录 valid_loss\n",
        "\n",
        "def objective(trial):\n",
        "    if trial is not None:\n",
        "        print('\\nNew trial here')\n",
        "        # 定义需要调优的超参数空间\n",
        "        config['learning_rate'] = trial.suggest_float('lr', 1e-6, 1e-3)\n",
        "        config['momentum'] = trial.suggest_float('momentum', 0, 0.7)\n",
        "        # config['batch_size'] = trial.suggest_categorical('batch_size', [128])\n",
        "        config['k'] = trial.suggest_int('k_feats', 1, 32)\n",
        "        # config['layer'][0] = config['k']\n",
        "    \n",
        "    # 打印所需的超参数\n",
        "    print(f'''hyper-parameter: \n",
        "        optimizer: {config['optim']},\n",
        "        lr: {config['learning_rate']}, \n",
        "        momentum: {config['momentum']},\n",
        "        select_feats: {config['k']}, \n",
        "        layer: {config['layer']}''')\n",
        "    \n",
        "    global valid_losses\n",
        "    # global valid_scores\n",
        "    # 每次 trial 初始化 valid_scores，可以不初始化，通过 trial * k + fold 来访问当前 trial 的 valid_score，\n",
        "    # 这样可以让 trainer() 保存 trials 中最好的模型参数，但这并不意味着该参数对应的 k-fold validation loss 最低。\n",
        "    # valid_scores = []\n",
        "    # for fold in range(k):\n",
        "    #     # Data split\n",
        "    #     valid_data = training_data[num_valid_samples * fold:\n",
        "    #                             num_valid_samples * (fold + 1)]\n",
        "    #     train_data = np.concatenate((\n",
        "    #         training_data[:num_valid_samples * fold],\n",
        "    #         training_data[num_valid_samples * (fold + 1):]))\n",
        "\n",
        "    # Normalization\n",
        "    if not config['no_normal']:\n",
        "        train_mean = np.mean(train_data[:, 35:-1], axis=0)  # 前 35 列为 one-hot vector，我并没有对他们做 normalization，可以自行设置\n",
        "        train_std = np.std(train_data[:, 35:-1], axis=0)\n",
        "        train_data[:, 35:-1] -= train_mean\n",
        "        train_data[:, 35:-1] /= train_std\n",
        "        valid_data[:, 35:-1] -= train_mean\n",
        "        valid_data[:, 35:-1] /= train_std\n",
        "        test_data[:, 35:] -= train_mean\n",
        "        test_data[:, 35:] /= train_std\n",
        "\n",
        "    x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['no_select_all'])\n",
        "    # Print out the data size.\n",
        "    print(f\"\"\"train_data size: {x_train.shape} \n",
        "    valid_data size: {x_valid.shape} \n",
        "    test_data size: {x_test.shape}\"\"\")\n",
        "\n",
        "    train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n",
        "                                            COVID19Dataset(x_valid, y_valid), \\\n",
        "                                            COVID19Dataset(x_test)\n",
        "\n",
        "    # Pytorch data loader loads pytorch dataset into batches.\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
        "    \n",
        "    model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n",
        "    best_loss = trainer(train_loader, valid_loader, model, config, device)\n",
        "    # valid_scores.append(valid_score)\n",
        "    valid_losses.append(best_loss)\n",
        "    # if not config['no_k_cross']:\n",
        "    #     break\n",
        "        \n",
        "    # if valid_score > 2:\n",
        "    #     print(f'在第{fold+1}折上欠拟合') # 提前终止，减少计算资源\n",
        "    #     break       \n",
        "    \n",
        "    print(f'best_loss: {best_loss}')\n",
        "    \n",
        "    if best_loss<min(valid_losses):\n",
        "        model = My_Model(input_dim=x_test.shape[1]).to(device)\n",
        "        model.load_state_dict(torch.load(config['save_path']))\n",
        "        preds = predict(test_loader, model, device)\n",
        "        save_pred(preds, 'submission.csv')\n",
        "\n",
        "    if trial is not None:\n",
        "        return best_loss\n",
        "    else:\n",
        "        return x_test, test_loader\n",
        "\n",
        "\n",
        "\n",
        "AUTO_TUNE_PARAM = False  # Whether to tune parameters automatically\n",
        "\n",
        "if AUTO_TUNE_PARAM:\n",
        "    # 使用Optuna库进行超参数搜索\n",
        "    n_trials = 20  # 设置试验数量\n",
        "    print(f'AUTO_TUNE_PARAM: {AUTO_TUNE_PARAM}\\nn_trials: {n_trials}')\n",
        "    study = optuna.create_study(pruner=optuna.pruners.MedianPruner(), direction='minimize')\n",
        "    \n",
        "    # sample config\n",
        "    study.enqueue_trial(\n",
        "    {\n",
        "        \"lr\": 1e-5,\n",
        "        \"momentum\": 0.7,\n",
        "        \"k\": 88,\n",
        "    }\n",
        ")\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "    # 输出最优的超参数组合和性能指标\n",
        "    print('Best hyperparameters: {}'.format(study.best_params))\n",
        "    print('Best performance: {:.4f}'.format(study.best_value))\n",
        "    x_test, test_loader = objective(None)\n",
        "else:\n",
        "    # 注意，只有非自动调参时才进行了predict，节省一下计算资源\n",
        "    print(f'You could set AUTO_TUNE_PARAM True to tune parameters automatically.\\nAUTO_TUNE_PARAM: {AUTO_TUNE_PARAM}')\n",
        "    x_test, test_loader = objective(None)\n",
        "    model = My_Model(input_dim=x_test.shape[1]).to(device)\n",
        "    model.load_state_dict(torch.load(config['save_path']))\n",
        "    preds = predict(test_loader, model, device)\n",
        "    save_pred(preds, 'submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ_k5rY0GvSV"
      },
      "source": [
        "# Reference\n",
        "This notebook uses code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
